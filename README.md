# Spark com Pyspark

<br><br>
<img src="https://github.com/StunKnife/Pyspark/blob/main/figuras/fig_1_pyspark.png" width="1000">

# O que é o Spark?

  1. Ferramenta de Processamento de Dados (Não é Data Storage) 
  2. Distribuído em um Cluster
  3. Em memória
  4. Veloz
  5. Escalável
  6. Dados em HDFS ou Cloud
  7. Particionamento

O Spark também permite **Replicação** e tem **Tolerância a Falha**. 
    • Dados são copiados entre os nós do cluster. Isso traz o benefício de, entre outras coisas, tolerância a falhas
 <br><br>
 <img src="https://github.com/StunKnife/Pyspark/blob/main/figuras/cluster.png" width="1000">

 # Porque utilizar Spark frente a outras linguagens como Python ou R?
 
 Primeiro, você precisa Processar dados! Além disso, o Spark apresenta as seguintes vantagens:
     
    • Custo computacional: CPU, Memória, Rede etc.
    
    • Spark tem arquitetura voltada a processar dados!
    
    • Melhor performance, porém:    
        1. Não substitui Python
        2. Não substitui SQL ou um SGBDR

 
 <img align='right' src="https://github.com/StunKnife/Pyspark/blob/main/figuras/cluster.png" width="230">
